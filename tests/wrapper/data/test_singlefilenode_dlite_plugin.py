"""
Testing the functionalities of premod plugin
"""

import dlite
from pathlib import Path
from execflow.data.singlefile_converter import singlefile_converter

# from ../../dlite_plugins.plugin_premod import plugin_premod

testdir = Path(__file__).resolve().parent.parent.parent
# plugindir = root / "dlite_plugins"
#entitiesdir = root / "entities"
sampledir = testdir / "samples" 
# adding all the DLite storage plugin stored in the folder
#dlite.python_storage_plugin_path.append(plugindir)

# adding the entities contained in the folder to the storage
#dlite.storage_path.append(sampledir / "DLiteDataModelReaction.json")


# if True:
def test_singlefilenode_using_converter_w_abaqusdriver():
    """
    The using the singlefilenodeplugin using another plugin
    """

    #dlite.storage_path.append(entitiesdir)
    dlite.storage_path.append(sampledir / "DLiteDataModelReaction.json")
    sample = sampledir / "dlite_instance_reaction.json"
    # Create a singlefiledatanode instance witht the content equal
    # to the file generated by Abaqus

    # Note that if getting this instance does not work it might be because
    # the sintef entities-service is not running.
    # This can be checked by pasting the url in the browser
    DataModel = dlite.get_instance("http://onto-ns.com/meta/2.0/core.singlefile")
    with open(sample, "rb") as f:
        content = f.read()

    singlefileinst = DataModel(dimensions=(len(content),))
    singlefileinst.content = content

    instance_from_singlefiledatanode = singlefile_converter(
        singlefileinst, parse_driver="json", options="mode=r"
    )

    direct_instance = dlite.Instance.from_location(
        "json", sample, options="mode=r"
    )

    assert (
        instance_from_singlefiledatanode.properties.keys()
        == direct_instance.properties.keys()
    )

    for key in instance_from_singlefiledatanode.properties.keys():
        assert (
            instance_from_singlefiledatanode.properties[key]
            == direct_instance.properties[key]
        ).all()
